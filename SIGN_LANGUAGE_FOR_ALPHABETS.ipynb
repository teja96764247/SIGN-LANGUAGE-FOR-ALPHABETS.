{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "bxhc97RWQ_Pv"
      },
      "outputs": [],
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d muhammadkhalid/sign-language-for-alphabets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0d-Hih8RX45P",
        "outputId": "e6153a02-a9e4-4a32-d4f3-635cb94e2348"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sign-language-for-alphabets.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from zipfile import ZipFile\n",
        "dataset = '/content/sign-language-for-alphabets.zip'\n",
        "\n",
        "with ZipFile(dataset,'r') as zip:\n",
        "  zip.extractall()\n",
        "  print('The dataset is extracted')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ztnYbZvjX5By",
        "outputId": "3a44afd9-ff85-42a6-8780-1d648e5c6055"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The dataset is extracted\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "from PIL import Image"
      ],
      "metadata": {
        "id": "3YIxbsxBYTPj"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sign_folder=os.listdir('/content/Sign Language for Alphabets')\n",
        "print(sign_folder)\n",
        "print(len(sign_folder))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qwLjG03JYkxR",
        "outputId": "0664ad70-7063-4649-bf64-acfb2df1cc21"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['s', 'z', 'w', 'p', 'd', 'j', 'r', 'f', 'n', 'y', 'k', 'e', 'o', 'g', 'b', 'u', 't', 'c', 'a', 'unknown', 'x', 'm', 'v', 'i', 'l', 'q', 'h']\n",
            "27\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data=[]"
      ],
      "metadata": {
        "id": "2I_ejdOWaDin"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(27):\n",
        "  folder_path='/content/Sign Language for Alphabets/'+sign_folder[i]\n",
        "  img_folder=os.listdir(folder_path)\n",
        "  l=len(img_folder)\n",
        "  for j in range(l):\n",
        "    img_path=folder_path+'/'+img_folder[j]\n",
        "    img_pillow=Image.open(img_path)\n",
        "    img_color=img_pillow.convert('RGB')\n",
        "    img_resize=img_color.resize((64,64))\n",
        "    img_arr=np.array(img_resize)\n",
        "    data.append([img_arr,i])"
      ],
      "metadata": {
        "id": "dxSFsbZqYuBJ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x=[]\n",
        "y=[]\n",
        "for img,symbol in data:\n",
        "  x.append(img)\n",
        "  y.append(symbol)"
      ],
      "metadata": {
        "id": "FGm7AeJ7ZaZk"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x1=np.array(x)\n",
        "y1=np.array(y)"
      ],
      "metadata": {
        "id": "ZeFhCQOJau8K"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train,x_test,y_train,y_test=train_test_split(x1,y1,test_size=0.2,random_state=0)"
      ],
      "metadata": {
        "id": "VBLCPYx2aWwz"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_scaled=x_train/255\n",
        "x_test_scaled=x_test/255"
      ],
      "metadata": {
        "id": "LspXUoJdanZL"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ],
      "metadata": {
        "id": "x3ATzb7FatHp"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_of_classes=28\n",
        "model=keras.Sequential()\n",
        "\n",
        "model.add(keras.layers.Conv2D(32,kernel_size=(3,3),activation='relu',input_shape=(64,64,3)))\n",
        "model.add(keras.layers.MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "model.add(keras.layers.Conv2D(64,kernel_size=(3,3),activation='relu'))\n",
        "model.add(keras.layers.MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "model.add(keras.layers.Flatten())\n",
        "\n",
        "model.add(keras.layers.Dense(128,activation='relu'))\n",
        "model.add(keras.layers.Dropout(0.5))\n",
        "\n",
        "model.add(keras.layers.Dense(64,activation='relu'))\n",
        "model.add(keras.layers.Dropout(0.5))\n",
        "\n",
        "model.add(keras.layers.Dense(num_of_classes,activation='softmax'))"
      ],
      "metadata": {
        "id": "qzhqiNJHbBjS"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "H1MIj9EpbOV7"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x_train_scaled,y_train,epochs=100,validation_split=0.1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pCIeThvEbY4q",
        "outputId": "c53c34e1-8804-4638-b64c-b272600ec60f"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "912/912 [==============================] - 13s 7ms/step - loss: 2.1119 - accuracy: 0.3770 - val_loss: 1.0075 - val_accuracy: 0.7333\n",
            "Epoch 2/100\n",
            "912/912 [==============================] - 6s 7ms/step - loss: 1.2058 - accuracy: 0.6284 - val_loss: 0.6726 - val_accuracy: 0.8056\n",
            "Epoch 3/100\n",
            "912/912 [==============================] - 6s 6ms/step - loss: 0.9094 - accuracy: 0.7120 - val_loss: 0.5130 - val_accuracy: 0.8522\n",
            "Epoch 4/100\n",
            "912/912 [==============================] - 6s 7ms/step - loss: 0.7784 - accuracy: 0.7512 - val_loss: 0.4236 - val_accuracy: 0.8818\n",
            "Epoch 5/100\n",
            "912/912 [==============================] - 6s 6ms/step - loss: 0.6833 - accuracy: 0.7850 - val_loss: 0.3774 - val_accuracy: 0.8914\n",
            "Epoch 6/100\n",
            "912/912 [==============================] - 6s 7ms/step - loss: 0.6134 - accuracy: 0.8056 - val_loss: 0.3436 - val_accuracy: 0.9025\n",
            "Epoch 7/100\n",
            "912/912 [==============================] - 6s 6ms/step - loss: 0.5559 - accuracy: 0.8240 - val_loss: 0.3134 - val_accuracy: 0.9086\n",
            "Epoch 8/100\n",
            "912/912 [==============================] - 6s 7ms/step - loss: 0.5114 - accuracy: 0.8359 - val_loss: 0.2987 - val_accuracy: 0.9099\n",
            "Epoch 9/100\n",
            "912/912 [==============================] - 6s 6ms/step - loss: 0.4747 - accuracy: 0.8490 - val_loss: 0.2698 - val_accuracy: 0.9244\n",
            "Epoch 10/100\n",
            "912/912 [==============================] - 6s 7ms/step - loss: 0.4396 - accuracy: 0.8588 - val_loss: 0.2796 - val_accuracy: 0.9213\n",
            "Epoch 11/100\n",
            "912/912 [==============================] - 6s 7ms/step - loss: 0.4179 - accuracy: 0.8657 - val_loss: 0.2507 - val_accuracy: 0.9253\n",
            "Epoch 12/100\n",
            "912/912 [==============================] - 6s 7ms/step - loss: 0.3960 - accuracy: 0.8724 - val_loss: 0.2422 - val_accuracy: 0.9312\n",
            "Epoch 13/100\n",
            "912/912 [==============================] - 6s 7ms/step - loss: 0.3723 - accuracy: 0.8812 - val_loss: 0.2281 - val_accuracy: 0.9355\n",
            "Epoch 14/100\n",
            "912/912 [==============================] - 6s 7ms/step - loss: 0.3527 - accuracy: 0.8856 - val_loss: 0.2301 - val_accuracy: 0.9377\n",
            "Epoch 15/100\n",
            "912/912 [==============================] - 6s 7ms/step - loss: 0.3500 - accuracy: 0.8896 - val_loss: 0.2413 - val_accuracy: 0.9333\n",
            "Epoch 16/100\n",
            "912/912 [==============================] - 9s 10ms/step - loss: 0.3274 - accuracy: 0.8943 - val_loss: 0.2185 - val_accuracy: 0.9398\n",
            "Epoch 17/100\n",
            "912/912 [==============================] - 7s 8ms/step - loss: 0.3167 - accuracy: 0.8984 - val_loss: 0.2137 - val_accuracy: 0.9392\n",
            "Epoch 18/100\n",
            "912/912 [==============================] - 7s 8ms/step - loss: 0.3050 - accuracy: 0.9034 - val_loss: 0.2227 - val_accuracy: 0.9448\n",
            "Epoch 19/100\n",
            "912/912 [==============================] - 7s 8ms/step - loss: 0.2882 - accuracy: 0.9092 - val_loss: 0.2044 - val_accuracy: 0.9454\n",
            "Epoch 20/100\n",
            "912/912 [==============================] - 8s 9ms/step - loss: 0.2956 - accuracy: 0.9073 - val_loss: 0.2279 - val_accuracy: 0.9392\n",
            "Epoch 21/100\n",
            "912/912 [==============================] - 6s 6ms/step - loss: 0.2784 - accuracy: 0.9108 - val_loss: 0.2138 - val_accuracy: 0.9395\n",
            "Epoch 22/100\n",
            "912/912 [==============================] - 6s 7ms/step - loss: 0.2671 - accuracy: 0.9137 - val_loss: 0.2122 - val_accuracy: 0.9441\n",
            "Epoch 23/100\n",
            "912/912 [==============================] - 6s 6ms/step - loss: 0.2677 - accuracy: 0.9147 - val_loss: 0.2013 - val_accuracy: 0.9417\n",
            "Epoch 24/100\n",
            "912/912 [==============================] - 8s 9ms/step - loss: 0.2589 - accuracy: 0.9180 - val_loss: 0.2200 - val_accuracy: 0.9404\n",
            "Epoch 25/100\n",
            "912/912 [==============================] - 7s 8ms/step - loss: 0.2469 - accuracy: 0.9203 - val_loss: 0.2331 - val_accuracy: 0.9414\n",
            "Epoch 26/100\n",
            "912/912 [==============================] - 9s 9ms/step - loss: 0.2401 - accuracy: 0.9224 - val_loss: 0.2390 - val_accuracy: 0.9380\n",
            "Epoch 27/100\n",
            "912/912 [==============================] - 7s 7ms/step - loss: 0.2398 - accuracy: 0.9238 - val_loss: 0.2343 - val_accuracy: 0.9373\n",
            "Epoch 28/100\n",
            "912/912 [==============================] - 7s 7ms/step - loss: 0.2309 - accuracy: 0.9261 - val_loss: 0.2333 - val_accuracy: 0.9417\n",
            "Epoch 29/100\n",
            "912/912 [==============================] - 6s 7ms/step - loss: 0.2304 - accuracy: 0.9238 - val_loss: 0.2147 - val_accuracy: 0.9466\n",
            "Epoch 30/100\n",
            "912/912 [==============================] - 7s 8ms/step - loss: 0.2199 - accuracy: 0.9286 - val_loss: 0.2108 - val_accuracy: 0.9454\n",
            "Epoch 31/100\n",
            "912/912 [==============================] - 7s 7ms/step - loss: 0.2177 - accuracy: 0.9307 - val_loss: 0.2051 - val_accuracy: 0.9460\n",
            "Epoch 32/100\n",
            "912/912 [==============================] - 9s 10ms/step - loss: 0.2123 - accuracy: 0.9317 - val_loss: 0.2116 - val_accuracy: 0.9494\n",
            "Epoch 33/100\n",
            "912/912 [==============================] - 7s 7ms/step - loss: 0.2131 - accuracy: 0.9309 - val_loss: 0.2053 - val_accuracy: 0.9491\n",
            "Epoch 34/100\n",
            "912/912 [==============================] - 7s 8ms/step - loss: 0.2112 - accuracy: 0.9332 - val_loss: 0.2430 - val_accuracy: 0.9451\n",
            "Epoch 35/100\n",
            "912/912 [==============================] - 6s 7ms/step - loss: 0.2104 - accuracy: 0.9359 - val_loss: 0.2021 - val_accuracy: 0.9509\n",
            "Epoch 36/100\n",
            "912/912 [==============================] - 6s 7ms/step - loss: 0.2011 - accuracy: 0.9361 - val_loss: 0.2300 - val_accuracy: 0.9429\n",
            "Epoch 37/100\n",
            "912/912 [==============================] - 8s 9ms/step - loss: 0.1955 - accuracy: 0.9364 - val_loss: 0.2230 - val_accuracy: 0.9503\n",
            "Epoch 38/100\n",
            "912/912 [==============================] - 7s 8ms/step - loss: 0.2001 - accuracy: 0.9357 - val_loss: 0.2380 - val_accuracy: 0.9497\n",
            "Epoch 39/100\n",
            "912/912 [==============================] - 7s 8ms/step - loss: 0.2006 - accuracy: 0.9385 - val_loss: 0.2522 - val_accuracy: 0.9494\n",
            "Epoch 40/100\n",
            "912/912 [==============================] - 8s 8ms/step - loss: 0.1847 - accuracy: 0.9400 - val_loss: 0.2160 - val_accuracy: 0.9519\n",
            "Epoch 41/100\n",
            "912/912 [==============================] - 10s 11ms/step - loss: 0.1844 - accuracy: 0.9401 - val_loss: 0.2231 - val_accuracy: 0.9497\n",
            "Epoch 42/100\n",
            "912/912 [==============================] - 7s 8ms/step - loss: 0.1805 - accuracy: 0.9402 - val_loss: 0.2154 - val_accuracy: 0.9522\n",
            "Epoch 43/100\n",
            "912/912 [==============================] - 6s 7ms/step - loss: 0.1819 - accuracy: 0.9422 - val_loss: 0.2263 - val_accuracy: 0.9494\n",
            "Epoch 44/100\n",
            "912/912 [==============================] - 6s 7ms/step - loss: 0.1877 - accuracy: 0.9406 - val_loss: 0.2278 - val_accuracy: 0.9485\n",
            "Epoch 45/100\n",
            "912/912 [==============================] - 6s 7ms/step - loss: 0.1743 - accuracy: 0.9446 - val_loss: 0.2387 - val_accuracy: 0.9519\n",
            "Epoch 46/100\n",
            "912/912 [==============================] - 6s 6ms/step - loss: 0.1808 - accuracy: 0.9427 - val_loss: 0.2128 - val_accuracy: 0.9509\n",
            "Epoch 47/100\n",
            "912/912 [==============================] - 6s 7ms/step - loss: 0.1763 - accuracy: 0.9430 - val_loss: 0.2160 - val_accuracy: 0.9525\n",
            "Epoch 48/100\n",
            "912/912 [==============================] - 6s 6ms/step - loss: 0.1742 - accuracy: 0.9455 - val_loss: 0.2010 - val_accuracy: 0.9562\n",
            "Epoch 49/100\n",
            "912/912 [==============================] - 6s 7ms/step - loss: 0.1761 - accuracy: 0.9447 - val_loss: 0.2154 - val_accuracy: 0.9519\n",
            "Epoch 50/100\n",
            "912/912 [==============================] - 6s 6ms/step - loss: 0.1760 - accuracy: 0.9437 - val_loss: 0.2150 - val_accuracy: 0.9478\n",
            "Epoch 51/100\n",
            "912/912 [==============================] - 7s 7ms/step - loss: 0.1683 - accuracy: 0.9475 - val_loss: 0.1966 - val_accuracy: 0.9506\n",
            "Epoch 52/100\n",
            "912/912 [==============================] - 6s 6ms/step - loss: 0.1729 - accuracy: 0.9466 - val_loss: 0.2298 - val_accuracy: 0.9552\n",
            "Epoch 53/100\n",
            "912/912 [==============================] - 7s 8ms/step - loss: 0.1606 - accuracy: 0.9496 - val_loss: 0.2619 - val_accuracy: 0.9540\n",
            "Epoch 54/100\n",
            "912/912 [==============================] - 6s 6ms/step - loss: 0.1679 - accuracy: 0.9477 - val_loss: 0.2068 - val_accuracy: 0.9543\n",
            "Epoch 55/100\n",
            "912/912 [==============================] - 6s 7ms/step - loss: 0.1613 - accuracy: 0.9487 - val_loss: 0.2435 - val_accuracy: 0.9466\n",
            "Epoch 56/100\n",
            "912/912 [==============================] - 6s 7ms/step - loss: 0.1611 - accuracy: 0.9496 - val_loss: 0.2623 - val_accuracy: 0.9497\n",
            "Epoch 57/100\n",
            "912/912 [==============================] - 6s 7ms/step - loss: 0.1600 - accuracy: 0.9503 - val_loss: 0.2354 - val_accuracy: 0.9546\n",
            "Epoch 58/100\n",
            "912/912 [==============================] - 6s 7ms/step - loss: 0.1568 - accuracy: 0.9505 - val_loss: 0.2183 - val_accuracy: 0.9543\n",
            "Epoch 59/100\n",
            "912/912 [==============================] - 6s 6ms/step - loss: 0.1562 - accuracy: 0.9489 - val_loss: 0.2611 - val_accuracy: 0.9481\n",
            "Epoch 60/100\n",
            "912/912 [==============================] - 7s 7ms/step - loss: 0.1546 - accuracy: 0.9500 - val_loss: 0.2272 - val_accuracy: 0.9531\n",
            "Epoch 61/100\n",
            "912/912 [==============================] - 6s 6ms/step - loss: 0.1541 - accuracy: 0.9527 - val_loss: 0.2226 - val_accuracy: 0.9512\n",
            "Epoch 62/100\n",
            "912/912 [==============================] - 6s 7ms/step - loss: 0.1459 - accuracy: 0.9540 - val_loss: 0.2936 - val_accuracy: 0.9534\n",
            "Epoch 63/100\n",
            "912/912 [==============================] - 6s 6ms/step - loss: 0.1513 - accuracy: 0.9523 - val_loss: 0.2142 - val_accuracy: 0.9537\n",
            "Epoch 64/100\n",
            "912/912 [==============================] - 6s 7ms/step - loss: 0.1557 - accuracy: 0.9513 - val_loss: 0.2295 - val_accuracy: 0.9546\n",
            "Epoch 65/100\n",
            "912/912 [==============================] - 6s 6ms/step - loss: 0.1565 - accuracy: 0.9497 - val_loss: 0.2595 - val_accuracy: 0.9537\n",
            "Epoch 66/100\n",
            "912/912 [==============================] - 6s 7ms/step - loss: 0.1482 - accuracy: 0.9535 - val_loss: 0.2337 - val_accuracy: 0.9546\n",
            "Epoch 67/100\n",
            "912/912 [==============================] - 6s 6ms/step - loss: 0.1467 - accuracy: 0.9545 - val_loss: 0.2961 - val_accuracy: 0.9506\n",
            "Epoch 68/100\n",
            "912/912 [==============================] - 6s 7ms/step - loss: 0.1502 - accuracy: 0.9537 - val_loss: 0.2837 - val_accuracy: 0.9512\n",
            "Epoch 69/100\n",
            "912/912 [==============================] - 6s 7ms/step - loss: 0.1477 - accuracy: 0.9545 - val_loss: 0.2474 - val_accuracy: 0.9506\n",
            "Epoch 70/100\n",
            "912/912 [==============================] - 6s 6ms/step - loss: 0.1463 - accuracy: 0.9539 - val_loss: 0.2496 - val_accuracy: 0.9519\n",
            "Epoch 71/100\n",
            "912/912 [==============================] - 6s 7ms/step - loss: 0.1502 - accuracy: 0.9537 - val_loss: 0.2586 - val_accuracy: 0.9441\n",
            "Epoch 72/100\n",
            "912/912 [==============================] - 6s 6ms/step - loss: 0.1466 - accuracy: 0.9536 - val_loss: 0.2927 - val_accuracy: 0.9512\n",
            "Epoch 73/100\n",
            "912/912 [==============================] - 6s 7ms/step - loss: 0.1433 - accuracy: 0.9548 - val_loss: 0.2494 - val_accuracy: 0.9522\n",
            "Epoch 74/100\n",
            "912/912 [==============================] - 6s 6ms/step - loss: 0.1459 - accuracy: 0.9540 - val_loss: 0.2473 - val_accuracy: 0.9485\n",
            "Epoch 75/100\n",
            "912/912 [==============================] - 6s 7ms/step - loss: 0.1398 - accuracy: 0.9552 - val_loss: 0.2930 - val_accuracy: 0.9506\n",
            "Epoch 76/100\n",
            "912/912 [==============================] - 6s 6ms/step - loss: 0.1480 - accuracy: 0.9544 - val_loss: 0.2403 - val_accuracy: 0.9506\n",
            "Epoch 77/100\n",
            "912/912 [==============================] - 6s 7ms/step - loss: 0.1452 - accuracy: 0.9562 - val_loss: 0.3246 - val_accuracy: 0.9540\n",
            "Epoch 78/100\n",
            "912/912 [==============================] - 6s 6ms/step - loss: 0.1372 - accuracy: 0.9564 - val_loss: 0.2326 - val_accuracy: 0.9540\n",
            "Epoch 79/100\n",
            "912/912 [==============================] - 6s 7ms/step - loss: 0.1402 - accuracy: 0.9569 - val_loss: 0.2531 - val_accuracy: 0.9410\n",
            "Epoch 80/100\n",
            "912/912 [==============================] - 6s 6ms/step - loss: 0.1280 - accuracy: 0.9596 - val_loss: 0.3712 - val_accuracy: 0.9481\n",
            "Epoch 81/100\n",
            "912/912 [==============================] - 6s 7ms/step - loss: 0.1417 - accuracy: 0.9566 - val_loss: 0.2540 - val_accuracy: 0.9552\n",
            "Epoch 82/100\n",
            "912/912 [==============================] - 6s 7ms/step - loss: 0.1334 - accuracy: 0.9582 - val_loss: 0.2457 - val_accuracy: 0.9552\n",
            "Epoch 83/100\n",
            "912/912 [==============================] - 6s 6ms/step - loss: 0.1346 - accuracy: 0.9586 - val_loss: 0.2297 - val_accuracy: 0.9506\n",
            "Epoch 84/100\n",
            "912/912 [==============================] - 6s 7ms/step - loss: 0.1444 - accuracy: 0.9556 - val_loss: 0.2393 - val_accuracy: 0.9352\n",
            "Epoch 85/100\n",
            "912/912 [==============================] - 6s 6ms/step - loss: 0.1413 - accuracy: 0.9556 - val_loss: 0.2488 - val_accuracy: 0.9537\n",
            "Epoch 86/100\n",
            "912/912 [==============================] - 6s 7ms/step - loss: 0.1370 - accuracy: 0.9572 - val_loss: 0.2574 - val_accuracy: 0.9525\n",
            "Epoch 87/100\n",
            "912/912 [==============================] - 6s 6ms/step - loss: 0.1294 - accuracy: 0.9589 - val_loss: 0.2475 - val_accuracy: 0.9559\n",
            "Epoch 88/100\n",
            "912/912 [==============================] - 6s 7ms/step - loss: 0.1346 - accuracy: 0.9585 - val_loss: 0.2522 - val_accuracy: 0.9463\n",
            "Epoch 89/100\n",
            "912/912 [==============================] - 6s 6ms/step - loss: 0.1420 - accuracy: 0.9574 - val_loss: 0.2822 - val_accuracy: 0.9531\n",
            "Epoch 90/100\n",
            "912/912 [==============================] - 6s 7ms/step - loss: 0.1378 - accuracy: 0.9584 - val_loss: 0.2703 - val_accuracy: 0.9537\n",
            "Epoch 91/100\n",
            "912/912 [==============================] - 6s 6ms/step - loss: 0.1290 - accuracy: 0.9603 - val_loss: 0.2607 - val_accuracy: 0.9525\n",
            "Epoch 92/100\n",
            "912/912 [==============================] - 6s 7ms/step - loss: 0.1305 - accuracy: 0.9601 - val_loss: 0.2556 - val_accuracy: 0.9537\n",
            "Epoch 93/100\n",
            "912/912 [==============================] - 6s 7ms/step - loss: 0.1297 - accuracy: 0.9609 - val_loss: 0.2406 - val_accuracy: 0.9556\n",
            "Epoch 94/100\n",
            "912/912 [==============================] - 6s 6ms/step - loss: 0.1317 - accuracy: 0.9588 - val_loss: 0.2562 - val_accuracy: 0.9519\n",
            "Epoch 95/100\n",
            "912/912 [==============================] - 6s 7ms/step - loss: 0.1285 - accuracy: 0.9583 - val_loss: 0.2855 - val_accuracy: 0.9552\n",
            "Epoch 96/100\n",
            "912/912 [==============================] - 6s 6ms/step - loss: 0.1341 - accuracy: 0.9593 - val_loss: 0.2731 - val_accuracy: 0.9549\n",
            "Epoch 97/100\n",
            "912/912 [==============================] - 6s 7ms/step - loss: 0.1325 - accuracy: 0.9594 - val_loss: 0.2532 - val_accuracy: 0.9562\n",
            "Epoch 98/100\n",
            "912/912 [==============================] - 6s 6ms/step - loss: 0.1330 - accuracy: 0.9589 - val_loss: 0.2703 - val_accuracy: 0.9515\n",
            "Epoch 99/100\n",
            "912/912 [==============================] - 6s 7ms/step - loss: 0.1289 - accuracy: 0.9598 - val_loss: 0.3938 - val_accuracy: 0.9478\n",
            "Epoch 100/100\n",
            "912/912 [==============================] - 6s 6ms/step - loss: 0.1292 - accuracy: 0.9606 - val_loss: 0.2248 - val_accuracy: 0.9454\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x78e9a806eda0>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img_path='/content/Sign Language for Alphabets/h/h_1.jpg'\n",
        "img_pillow=Image.open(img_path)\n",
        "img_color=img_pillow.convert('RGB')\n",
        "img_resize=img_color.resize((64,64))\n",
        "img_arr=np.array(img_resize)\n",
        "img_scaled=img_arr/255\n",
        "img_reshape=np.reshape(img_scaled,[1,64,64,3])\n",
        "prediction=model.predict(img_reshape)\n",
        "print(prediction)\n",
        "output=np.argmax(prediction)\n",
        "print(output)\n",
        "if(output==0):\n",
        "  print('The Alphabet is S')\n",
        "elif(output==1):\n",
        "  print('The Alphabet is Z')\n",
        "elif(output==2):\n",
        "  print('The Alphabet is W')\n",
        "elif(output==3):\n",
        "  print('The Alphabet is P')\n",
        "elif(output==4):\n",
        "  print('The Alphabet is D')\n",
        "elif(output==5):\n",
        "  print('The Alphabet is J')\n",
        "elif(output==6):\n",
        "  print('The Alphabet is R')\n",
        "elif(output==7):\n",
        "  print('The Alphabet is F')\n",
        "elif(output==8):\n",
        "  print('The Alphabet is N')\n",
        "elif(output==9):\n",
        "  print('The Alphabet is Y')\n",
        "elif(output==10):\n",
        "  print('The Alphabet is K')\n",
        "elif(output==11):\n",
        "  print('The Alphabet is E')\n",
        "elif(output==12):\n",
        "  print('The Alphabet is O')\n",
        "elif(output==13):\n",
        "  print('The Alphabet is G')\n",
        "elif(output==14):\n",
        "  print('The Alphabet is B')\n",
        "elif(output==15):\n",
        "  print('The Alphabet is U')\n",
        "elif(output==16):\n",
        "  print('The Alphabet is C')\n",
        "elif(output==17):\n",
        "  print('The Alphabet is T')\n",
        "elif(output==18):\n",
        "  print('The Alphabet is A')\n",
        "elif(output==19):\n",
        "  print('The Alphabet is UNKNOW')\n",
        "elif(output==20):\n",
        "  print('The Alphabet is X')\n",
        "elif(output==21):\n",
        "  print('The Alphabet is M')\n",
        "elif(output==22):\n",
        "  print('The Alphabet is V')\n",
        "elif(output==23):\n",
        "  print('The Alphabet is I')\n",
        "elif(output==24):\n",
        "  print('The Alphabet is L')\n",
        "elif(output==25):\n",
        "  print('The Alphabet is Q')\n",
        "elif(output==26):\n",
        "  print('The Alphabet is H')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QeMfvOAIbfLg",
        "outputId": "d72b911d-4ff5-43a8-96e9-ea7ba9a4b5b3"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 19ms/step\n",
            "[[2.8788729e-24 3.1786677e-14 5.7811415e-21 6.9561395e-15 1.4139758e-14\n",
            "  1.6423644e-20 6.6710016e-22 2.2826525e-34 3.9789003e-35 0.0000000e+00\n",
            "  0.0000000e+00 5.2197513e-09 1.5332804e-31 7.8423081e-09 6.5580529e-33\n",
            "  1.2773352e-33 7.1202522e-24 2.4606719e-26 1.7869932e-14 1.1042161e-16\n",
            "  1.4945114e-07 2.6080069e-25 2.7602382e-28 4.0191501e-24 3.1559843e-28\n",
            "  1.7398370e-29 9.9999988e-01 0.0000000e+00]]\n",
            "26\n",
            "The Alphabet is H\n"
          ]
        }
      ]
    }
  ]
}